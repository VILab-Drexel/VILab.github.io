<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="SciIBI: Benchmarking Pedagogical Reasoning in K-12 Classroom Videos">
    <meta name="keywords" content="multimodal LLM, science instruction, K-12 education, NGSS, benchmark">

    <title>SciIBI - Visual Intelligence Lab</title>

    <!-- Bulma CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.9.4/css/bulma.min.css">

    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">

    <!-- Academicons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro&display=swap" rel="stylesheet">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="static/css/index.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="container">
            <div class="navbar-brand">
                <a class="navbar-item" href="../../index.html">
                    <span>Visual Intelligence Lab @ Drexel</span>
                </a>
                <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="navMenu">
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                    <span aria-hidden="true"></span>
                </a>
            </div>
            <div id="navMenu" class="navbar-menu">
                <div class="navbar-end">
                    <a class="navbar-item" href="../../index.html">
                        <span class="icon"><i class="fas fa-home"></i></span>
                        <span>Home</span>
                    </a>
                </div>
            </div>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero is-light">
        <div class="hero-body">
            <div class="container has-text-centered">
                <!-- Title -->
                <h1 class="publication-title">
                    Can Multimodal LLMs "See" Science Instruction?<br>
                    Benchmarking Pedagogical Reasoning in K-12 Classroom Videos
                </h1>

                <!-- Authors -->
                <div class="publication-authors">
                    <span class="author-block">
                        <a href="#">Yixuan Shen</a><sup>1*</sup>,
                    </span>
                    <span class="author-block">
                        <a href="#">Peng He</a><sup>2*</sup>,
                    </span>
                    <span class="author-block">
                        <a href="#">Honglu Liu</a><sup>2,3</sup>,
                    </span>
                    <span class="author-block">
                        <a href="#">Yuyang Ji</a><sup>1</sup>,
                    </span>
                    <span class="author-block">
                        <a href="#">Tingting Li</a><sup>2</sup>,
                    </span>
                    <span class="author-block">
                        <a href="#">Tianlong Chen</a><sup>4</sup>,
                    </span>
                    <span class="author-block">
                        <a href="#">Kaidi Xu</a><sup>5</sup>,
                    </span>
                    <span class="author-block">
                        <a href="#">Feng Liu</a><sup>1+</sup>
                    </span>
                </div>

                <!-- Author Notes -->
                <div class="author-notes">
                    <span>* Equal contribution</span>&nbsp;&nbsp;
                    <span>+ Corresponding author</span>
                </div>

                <!-- Affiliations -->
                <div class="publication-affiliations">
                    <span class="affiliation-block"><sup>1</sup>Drexel University</span>
                    <span class="affiliation-block"><sup>2</sup>Washington State University</span>
                    <span class="affiliation-block"><sup>3</sup>Beijing Normal University</span>
                    <span class="affiliation-block"><sup>4</sup>UNC Chapel Hill</span>
                    <span class="affiliation-block"><sup>5</sup>City University of Hong Kong</span>
                </div>

                <!-- Links -->
                <div class="publication-links">
                    <a class="button is-medium external-link" href="#">
                        <span class="icon"><i class="fas fa-file-pdf"></i></span>
                        <span>Paper</span>
                    </a>
                    <a class="button is-medium external-link is-disabled" href="#">
                        <span class="icon"><i class="ai ai-arxiv"></i></span>
                        <span>arXiv</span>
                    </a>
                    <a class="button is-medium external-link" href="https://github.com/VILab-Drexel/SciIBI" target="_blank">
                        <span class="icon"><i class="fab fa-github"></i></span>
                        <span>Code</span>
                    </a>
                    <a class="button is-medium external-link is-disabled" href="#">
                        <span class="icon"><i class="fas fa-database"></i></span>
                        <span>Data</span>
                    </a>
                </div>
            </div>
        </div>
    </section>

    <!-- Teaser Section -->
    <section class="section teaser">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <div class="has-text-centered">
                        <img src="static/images/figure1.png" alt="Visual Context Impact on CIP Classification" class="teaser-image">
                    </div>
                    <p class="teaser-caption">
                        <strong>Figure 1:</strong> MLLMs achieve different accuracy across CIP categories and show improvement with visual context.
                        Visual information provides essential contextual cues for understanding classroom instructional practices,
                        particularly in categories requiring observation of physical interactions and demonstrations.
                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Abstract Section -->
    <section class="section">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <h2 class="title is-3 section-title">Abstract</h2>
                    <div class="abstract-content">
                        <p>
                            While Multimodal Large Language Models (MLLMs) have shown promise in video understanding,
                            their ability to comprehend complex pedagogical practices in classroom settings remains
                            unexplored. We present <strong>SciIBI</strong> (Science Instructional Benchmarking for Instruction),
                            a benchmark for evaluating MLLMs on Classroom Instructional Practice (CIP) classification
                            aligned with the Next Generation Science Standards (NGSS). SciIBI comprises 113 video clips
                            from authentic K-12 science classrooms, each annotated with one of seven CIP categories
                            representing core instructional strategies. We evaluate eight state-of-the-art MLLMs using
                            various input modalities and prompting strategies. Our findings reveal that: (1) current
                            MLLMs struggle with pedagogical reasoning, with the best model achieving only 53.6% accuracy;
                            (2) visual context provides a +4.8% average improvement over transcript-only inputs; and
                            (3) certain instructional practices like "Developing Models" remain particularly challenging.
                            SciIBI provides a foundation for developing AI systems capable of supporting science
                            education research and teacher professional development.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Key Findings Section -->
    <section class="section key-findings">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <h2 class="title is-3 section-title">Key Findings</h2>
                    <div class="columns is-multiline">
                        <div class="column is-3">
                            <div class="finding-card">
                                <div class="finding-number">113</div>
                                <div class="finding-label">NGSS-Aligned Video Clips</div>
                            </div>
                        </div>
                        <div class="column is-3">
                            <div class="finding-card">
                                <div class="finding-number">8</div>
                                <div class="finding-label">State-of-the-Art MLLMs Evaluated</div>
                            </div>
                        </div>
                        <div class="column is-3">
                            <div class="finding-card">
                                <div class="finding-number">53.6%</div>
                                <div class="finding-label">Best Model Accuracy (InternVL3-78B)</div>
                            </div>
                        </div>
                        <div class="column is-3">
                            <div class="finding-card">
                                <div class="finding-number">+4.8%</div>
                                <div class="finding-label">Avg. Improvement with Visual Context</div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Benchmark Overview Section -->
    <section class="section">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <h2 class="title is-3 section-title">Benchmark Overview</h2>

                    <div class="benchmark-description">
                        <p>
                            SciIBI is designed to evaluate MLLMs' understanding of science instructional practices
                            in authentic K-12 classroom settings. The benchmark focuses on seven Classroom Instructional
                            Practice (CIP) categories derived from the NGSS framework:
                        </p>

                        <ul class="content-list">
                            <li><strong>Asking Questions:</strong> Teacher or students pose questions to guide inquiry</li>
                            <li><strong>Developing Models:</strong> Creating visual or physical representations of concepts</li>
                            <li><strong>Planning Investigations:</strong> Designing experiments and data collection methods</li>
                            <li><strong>Analyzing Data:</strong> Interpreting results and identifying patterns</li>
                            <li><strong>Mathematical Thinking:</strong> Using quantitative reasoning and calculations</li>
                            <li><strong>Constructing Explanations:</strong> Building evidence-based scientific explanations</li>
                            <li><strong>Engaging in Argument:</strong> Debating and defending scientific claims</li>
                        </ul>
                    </div>

                    <div class="has-text-centered" style="margin-top: 2rem;">
                        <img src="static/images/figure2.png" alt="CIP Category Distribution" class="benchmark-figure">
                        <p class="figure-caption">Figure 2: Distribution of CIP categories in the SciIBI benchmark.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Method Section -->
    <section class="section" style="background-color: #f5f5f5;">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <h2 class="title is-3 section-title">Method</h2>

                    <div class="method-content">
                        <h3 class="subsection-title">Input Modalities</h3>
                        <p>
                            We evaluate MLLMs using three input configurations to understand the contribution
                            of different modalities:
                        </p>
                        <ul class="content-list">
                            <li><strong>Transcript Only (T):</strong> Text transcripts of classroom dialogue</li>
                            <li><strong>Video Only (V):</strong> Visual frames sampled from video clips</li>
                            <li><strong>Video + Transcript (V+T):</strong> Combined multimodal input</li>
                        </ul>

                        <h3 class="subsection-title">Prompting Strategies</h3>
                        <p>
                            We employ multiple prompting approaches to comprehensively assess model capabilities:
                        </p>
                        <ul class="content-list">
                            <li><strong>Zero-shot:</strong> Direct classification without examples</li>
                            <li><strong>Zero-shot with CoT:</strong> Chain-of-thought reasoning for pedagogical analysis</li>
                            <li><strong>Few-shot:</strong> In-context examples of each CIP category</li>
                        </ul>
                    </div>

                    <div class="has-text-centered" style="margin-top: 2rem;">
                        <img src="static/images/figure3.png" alt="Evaluation Framework" class="method-figure">
                        <p class="figure-caption">Figure 3: Our evaluation framework for assessing MLLMs on pedagogical reasoning.</p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Results Section -->
    <section class="section">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <h2 class="title is-3 section-title">Results</h2>

                    <div class="table-container">
                        <table class="results-table">
                            <thead>
                                <tr>
                                    <th>Model</th>
                                    <th>Transcript (T)</th>
                                    <th>Video (V)</th>
                                    <th>Video+Transcript (V+T)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>GPT-4o</td>
                                    <td>42.5%</td>
                                    <td>38.1%</td>
                                    <td>45.1%</td>
                                </tr>
                                <tr>
                                    <td>Claude 3.5 Sonnet</td>
                                    <td>44.2%</td>
                                    <td>40.7%</td>
                                    <td>47.8%</td>
                                </tr>
                                <tr>
                                    <td>Gemini 1.5 Pro</td>
                                    <td>41.6%</td>
                                    <td>39.8%</td>
                                    <td>46.0%</td>
                                </tr>
                                <tr>
                                    <td>LLaVA-Video-72B</td>
                                    <td>38.9%</td>
                                    <td>35.4%</td>
                                    <td>42.5%</td>
                                </tr>
                                <tr>
                                    <td>Qwen2-VL-72B</td>
                                    <td>43.4%</td>
                                    <td>41.6%</td>
                                    <td>48.7%</td>
                                </tr>
                                <tr>
                                    <td>InternVL2.5-78B</td>
                                    <td>45.1%</td>
                                    <td>42.5%</td>
                                    <td>50.4%</td>
                                </tr>
                                <tr>
                                    <td>InternVL3-78B</td>
                                    <td>46.9%</td>
                                    <td>44.2%</td>
                                    <td class="best">53.6%</td>
                                </tr>
                                <tr>
                                    <td>Video-LLaMA-2</td>
                                    <td>36.3%</td>
                                    <td>33.6%</td>
                                    <td>40.7%</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                    <p class="figure-caption">Table 1: Classification accuracy across different models and input modalities using zero-shot prompting.</p>

                    <div class="highlight-box" style="margin-top: 2rem;">
                        <p>
                            <strong>Key Observation:</strong> All models show consistent improvement when combining
                            visual and textual information (V+T), with an average gain of +4.8% over transcript-only
                            baselines. This highlights the importance of visual context in understanding classroom
                            instructional practices.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- BibTeX Section -->
    <section class="section bibtex-section">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-10">
                    <h2 class="title is-3 section-title">BibTeX</h2>
                    <div class="bibtex-block">
                        <button class="copy-button" onclick="copyBibtex()">
                            <span class="icon"><i class="fas fa-copy"></i></span>
                            <span>Copy</span>
                        </button>
                        <pre id="bibtex-content">@article{shen2026sciibi,
  title={Can Multimodal LLMs "See" Science Instruction? Benchmarking Pedagogical Reasoning in K-12 Classroom Videos},
  author={Shen, Yixuan and He, Peng and Liu, Honglu and Ji, Yuyang and Li, Tingting and Chen, Tianlong and Xu, Kaidi and Liu, Feng},
  journal={arXiv preprint},
  year={2026}
}</pre>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <p>
                    &copy; 2026 <a href="../../index.html">Visual Intelligence Lab @ Drexel University</a>. All rights reserved.
                </p>
            </div>
        </div>
    </footer>

    <!-- Scripts -->
    <script>
        // Navbar burger toggle for mobile
        document.addEventListener('DOMContentLoaded', () => {
            const $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);
            if ($navbarBurgers.length > 0) {
                $navbarBurgers.forEach(el => {
                    el.addEventListener('click', () => {
                        const target = el.dataset.target;
                        const $target = document.getElementById(target);
                        el.classList.toggle('is-active');
                        $target.classList.toggle('is-active');
                    });
                });
            }
        });

        // Copy BibTeX to clipboard
        function copyBibtex() {
            const bibtex = document.getElementById('bibtex-content').innerText;
            navigator.clipboard.writeText(bibtex).then(() => {
                const btn = document.querySelector('.copy-button');
                btn.classList.add('copied');
                btn.innerHTML = '<span class="icon"><i class="fas fa-check"></i></span><span>Copied!</span>';
                setTimeout(() => {
                    btn.classList.remove('copied');
                    btn.innerHTML = '<span class="icon"><i class="fas fa-copy"></i></span><span>Copy</span>';
                }, 2000);
            });
        }
    </script>
</body>
</html>
